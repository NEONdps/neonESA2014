{
 "metadata": {
  "name": "",
  "signature": "sha256:dad1f86b963663de11cbbafd7612f03765abf56035a0f68ff3dab2cbc1b1e125"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from os import listdir\n",
      "import os.path as p\n",
      "import csv\n",
      "import h5py\n",
      "import numpy as np\n",
      "from collections import OrderedDict as od\n",
      "import pandas as pd\n",
      "\n",
      "mypath = \"HDF5Raw\"\n",
      "filePaths = []\n",
      "for i in listdir(mypath):\n",
      "    if not \"zip\" in i and not p.isfile(i):\n",
      "        for j in listdir(mypath+\"/\"+i):\n",
      "            if \"CSV\" in j:\n",
      "                filePaths.append(mypath+\"/\"+i+\"/\"+j)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extractHeader(f):\n",
      "    '''\n",
      "    Return all the header information of a NEON CSV\n",
      "    '''\n",
      "    with open(f) as csvfile:\n",
      "        neon = csv.reader(csvfile)\n",
      "        header = {}\n",
      "        for row in neon:\n",
      "            if \"#\" in row[0]:\n",
      "                if \"Product ID\" in row[0]:\n",
      "                    header[\"pid\"] = row[0].split(\":\")[1].strip()\n",
      "                elif \"Product Name\" in row[0]:\n",
      "                    header[\"pname\"] = row[0].split(\":\")[1].strip()\n",
      "                    header[\"time\"] = row[0].split(\":\")[1].strip()[0:2].strip()\n",
      "                elif \"Site:\" in row[0]:\n",
      "                    header[\"siteName\"] = row[0].split(\":\")[1].strip()\n",
      "                    header[\"site\"] = header[\"siteName\"][0:3]\n",
      "                elif \"Domain\" in row[0]:\n",
      "                    header[\"domain\"] = row[0].split(\":\")[1].strip()\n",
      "                elif \"Boom Level\" in row[0]:\n",
      "                    header[\"boomLevel\"] = row[0].split(\":\")[1].strip()\n",
      "                elif \"Units:\" in row[0]:\n",
      "                    header[\"units\"] = row[0].split(\":\")[1].strip()\n",
      "                elif \"(lat/long)\" in row[0]:\n",
      "                    header[\"latLon\"] = row[0].split(\":\")[1].strip()\n",
      "                elif \"Start Date\" in row[0]:\n",
      "                    header[\"day\"] = row[0].split(\":\")[1].strip()\n",
      "                elif \"Sensor information\" in row[0]:\n",
      "                    header[\"sensorType\"] = row[0].split(\":\")[1].strip()\n",
      "                elif \"Height Above\" in row[0]:\n",
      "                    header[\"sensorHeight\"] = row[0].split(\":\")[1].strip()\n",
      "                \n",
      "                    \n",
      "                    \n",
      "    return(header)\n",
      "\n",
      "def extractData(f):\n",
      "    '''\n",
      "    Extract the data from a NEON csv.  It returns it all as a dictionary.\n",
      "    '''\n",
      "    prow = 0\n",
      "    out = od([])\n",
      "    with open(f) as csvfile:\n",
      "        neon = csv.reader(csvfile)\n",
      "        for row in neon:\n",
      "            if not \"#\" in row[0]:\n",
      "                if \"#\" in prow[0]:\n",
      "                    for j in row:\n",
      "                        \n",
      "                        out[j] = []\n",
      "                else:\n",
      "                    for i,k in enumerate(out.keys()):\n",
      "                        out[k].append(row[i])\n",
      "                    \n",
      "            prow = row\n",
      "\n",
      "    return(out)\n",
      "\n",
      "def createPath(f):\n",
      "    '''\n",
      "    Return the full path to be used in the storage of an HDF5 file\n",
      "    '''\n",
      "    t = None\n",
      "    out = extractHeader(f)\n",
      "    d = out[\"domain\"].replace(\" \",\"_\")\n",
      "    boom = \"boom_\" + out[\"boomLevel\"]\n",
      "    if \"tower\" in boom:\n",
      "        boom = \"tower_top\"\n",
      "    time = \"min_\"+out[\"time\"]\n",
      "    if \"max\" in out[\"pname\"]:\n",
      "        t = \"Temp_maximum\"\n",
      "    elif \"varian\" in out[\"pname\"]:\n",
      "        t = \"Temp_variance\"\n",
      "    elif \"mini\" in out[\"pname\"]:\n",
      "        t = \"Temp_min\"\n",
      "    elif \"mean\" in out[\"pname\"]:\n",
      "        t = \"Temp_mean\"\n",
      "        \n",
      "    if t:\n",
      "        date = out[\"day\"]\n",
      "        path = d+\"/\"+out[\"site\"]+\"/\"+time+\"/\"+boom+\"/\"+date+\"/\"\n",
      "        return(path)\n",
      "    else:\n",
      "        return(None)\n",
      "    \n",
      "def createRecArray(dataframe):\n",
      "    '''\n",
      "    Take a pandas dataframe that's been processed and then return a numpy record array that can easily be written in HDF5\n",
      "    '''\n",
      "    dims = dataframe.shape\n",
      "    #dt = np.dtype({'names': ['date','numPts','mean','min','max','variance','stdErr','uncertainty'],'formats': ['a30','i4', 'f8','f8','f8','f8','f8','f8']})\n",
      "    dt = np.dtype([('date','a30'),('numPts','i4'),('mean','f8'),('min','f8'),('max','f8'),('variance','f8'),('stdErr','f8'),('uncertainty','f8')])\n",
      "    r = []\n",
      "    z = dataframe.as_matrix()\n",
      "    \n",
      "    for i in range(dims[0]):\n",
      "        tmpL = [None for _ in range(8)]\n",
      "        tmpL[0] = dataframe.index.values[i]\n",
      "        for j,n in enumerate(list(dataframe.columns.values)):\n",
      "\n",
      "            if \"max\" in n.lower():\n",
      "                tmpL[4] = float(z[i,j])\n",
      "            elif \"varian\" in n.lower():\n",
      "                tmpL[5] = float(z[i,j])\n",
      "            elif \"temperature min\" in n.lower():\n",
      "                tmpL[3] = float(z[i,j])\n",
      "            elif \"temperature mean\" in n.lower():\n",
      "                tmpL[2] = float(z[i,j])\n",
      "            elif \"number of points\" in n.lower():\n",
      "                tmpL[1] = int(z[i,j])\n",
      "            elif \"error\" in n.lower():\n",
      "                tmpL[6] = float(z[i,j])\n",
      "            elif \"uncertainty\" in n.lower():\n",
      "                tmpL[7] = float(z[i,j])\n",
      "                \n",
      "        r.append(tuple(tmpL))\n",
      "    r = np.array(r, dtype = dt)\n",
      "\n",
      "    ## Reshape the array\n",
      "    #r = r[['date','numPts','mean','min','max','variance','stdErr','uncertainty']].view(np.ndarray).reshape(len(r), -1)\n",
      " \n",
      "\n",
      "    return(r)\n",
      "\n",
      "def printname(name):\n",
      "    print name\n",
      "    \n",
      "def pWalk(p):\n",
      "    '''\n",
      "    Walk a path and return a nested list of paths\n",
      "    '''\n",
      "    ppath = p.split(\"/\")\n",
      "    out = []\n",
      "    for i in range(len(ppath)):\n",
      "        t = \"/\".join(ppath[0:(i+1)])\n",
      "        out.append(t)\n",
      "    return(out)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Create complete dictionary of files\n",
      "output = {}\n",
      "mdoutput = {}\n",
      "for i in filePaths:\n",
      "    path = createPath(i)\n",
      "    data = extractData(i)\n",
      "    if not path in output.keys() and path:\n",
      "        out = pd.DataFrame(data)\n",
      "        out = out.pivot(index=\"Start Date\", columns = \"Value Name\", values=\"Data 1\")\n",
      "        output[path] = out\n",
      "        mdoutput[path] = extractHeader(i)\n",
      "    elif path in output.keys() and path:\n",
      "        out = pd.DataFrame(data)\n",
      "        out = out.pivot(index=\"Start Date\", columns = \"Value Name\", values=\"Data 1\")\n",
      "        for j in list(out.columns.values):\n",
      "            output[path][j] = np.array(out[j],dtype=\"float\")\n",
      "### Now create dataframes that can be sorted\n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Code to combine dates\n",
      "## First parse keys\n",
      "nh = []\n",
      "for i in output.keys():\n",
      "    sh = i.split(\"/\")[:-2]\n",
      "    nht = \"/\".join(sh)\n",
      "    nh.append(nht)\n",
      "nhu = list(set(nh))\n",
      "\n",
      "\n",
      "hdfToWrite = {}\n",
      "newMD = {}\n",
      "for i in nhu:\n",
      "    tmpdict = {}\n",
      "    for j in output.keys():\n",
      "        if i in j:\n",
      "            k = j.split(\"/\")[-2:-1]\n",
      "            k = k[0].split(\"-\")[-1][0:2]\n",
      "            tmpdict[k] = output[j]\n",
      "    \n",
      "    newDF = tmpdict[\"01\"]\n",
      "    newDF = newDF.append(tmpdict[\"02\"])\n",
      "    newDF = newDF.append(tmpdict[\"03\"])\n",
      "    hdfToWrite[i] = newDF\n",
      "    \n",
      "    for j in mdoutput.keys():\n",
      "        if i in j:\n",
      "            newMD[i] = mdoutput[j]\n",
      "        \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Code to build the MD with keys that match the visit traverse of the HDF5\n",
      "fullP = []\n",
      "for i in newMD.keys():\n",
      "    fullP.extend(pWalk(i))\n",
      "fullP = list(set(fullP))\n",
      "\n",
      "traverseMD = {}\n",
      "for i in fullP:\n",
      "    if i == \"Domain_03/Ord\":\n",
      "        traverseMD[i] = {\"Site Name\":\"Ordway-Swisher Biological Station Site\",\"LatLon\":'29.68927/-81.99343'}\n",
      "    if i == \"Domain_10/Ste\":\n",
      "        traverseMD[i] = {\"Site Name\":'Sterling Site',\"LatLon\":'40.4619/-103.0293'}\n",
      "    if len(i.split(\"/\")) == 4:\n",
      "        traverseMD[i] = {\"Sensor Height\":newMD[i][\"sensorHeight\"] + \" m\",\"Sensor Type\":newMD[i][\"sensorType\"]}\n",
      "        traverseMD[(i+\"/temperature\")] = {\"Product Name\":newMD[i][\"pname\"],\"Product ID\":newMD[i][\"pid\"]}\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Script to write the HDF5 file\n",
      "f = h5py.File(\"/Users/thart/scratch/neonESA2014/data/fiuTestFile.hdf5\",\"w\")\n",
      "for i in hdfToWrite.keys():\n",
      "    \n",
      "    out = createRecArray(hdfToWrite[i])\n",
      "    dset = f.create_dataset(i+\"/temperature\",data=out)\n",
      "    dset.attrs[\"date\"] = \"Date and time of the first measurement\"\n",
      "    dset.attrs[\"numPts\"] = \"The number of points used to calculate each summary measure\"\n",
      "    dset.attrs[\"mean\"] = \"The mean temperature of numPts in Celcius, calculated over a given time range\"\n",
      "    dset.attrs[\"min\"] = \"The minimum temperature of numPts in Celcius, over a given time range\"\n",
      "    dset.attrs[\"max\"] = \"The maximum temperature of numPts in Celcius, over a given time range\"\n",
      "    dset.attrs[\"variance\"] = \"The variance temperature of numPts in Celcius, calculated over a given time range\"\n",
      "    dset.attrs[\"stdErr\"] = \"The standard error of the mean temperature of numPts in Celcius, calculated over a given time range\"\n",
      "    dset.attrs[\"uncertainty\"] = \"The uncertainty of the mean temperature, over a given time range, calculated from NEON.DOC.XXX\"\n",
      "    \n",
      "### add metadata as attributes\n",
      "\n",
      "for i in traverseMD.keys():\n",
      "    g = f[i]\n",
      "    for k,v in traverseMD[i].iteritems():\n",
      "        g.attrs[k] = v\n",
      "g = f[\"/\"]\n",
      "g.attrs[\"Abstract\"] = \"A sample NEON HDF5 data set for temperature data.  Created by E.M. Hart for the ESA 2014 workshop\"\n",
      "#g = f['Domain_03']\n",
      "##g.attrs[\"Domain Name\"] = \"Domain 3\"\n",
      "#f.visit(printname)\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = createRecArray(hdfToWrite[hdfToWrite.keys()[1]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test.shape\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 68,
       "text": [
        "(147,)"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = \"Domain_03/Ord/30_min/boom_1\"\n",
      "pWalk(test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "['Domain_03',\n",
        " 'Domain_03/Ord',\n",
        " 'Domain_03/Ord/30_min',\n",
        " 'Domain_03/Ord/30_min/boom_1']"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len('Domain_03/Ord/30_min/boom_1'.split(\"/\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 81,
       "text": [
        "4"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m = np.ones(3, dtype=np.dtype([('foo', int), ('bar', float)]))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# with heterogeneous dtype.\n",
      "struct_diffdtype = np.array([('2014-04-01 00:00:00.0', 1800, 21.529805774655536, 20.953231119594292, 21.90330409672651, 0.05863279566792817, 0.005707343985696955, 0.01864778738050875), ('2014-04-01 00:30:00.0', 1800, 20.124213100125626, 19.31790786313792, 21.150252598602947, 0.35156291750185226, 0.013975433157704753, 0.04035539883428007)],\n",
      "dtype=np.dtype([('date','a30'),('numPts','i4'),('mean','f8'),('min','f8'),('max','f8'),('variance','f8'),('stdErr','f8'),('uncertainty','f8')]))\n",
      "\n",
      "\n",
      "struct_diffdtype_nd = struct_diffdtype[['str_var', 'x', 'y']].view(np.ndarray).reshape(len(struct_diffdtype), -1)\n",
      "\n",
      "print struct_diffdtype\n",
      "\n",
      "print struct_diffdtype.shape\n",
      "\n",
      "print struct_diffdtype_nd\n",
      "\n",
      "print struct_diffdtype_nd.shape\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ ('2014-04-01 00:00:00.0', 1800, 21.529805774655536, 20.953231119594292, 21.90330409672651, 0.05863279566792817, 0.005707343985696955, 0.01864778738050875)\n",
        " ('2014-04-01 00:30:00.0', 1800, 20.124213100125626, 19.31790786313792, 21.150252598602947, 0.35156291750185226, 0.013975433157704753, 0.04035539883428007)]\n",
        "(2,)\n",
        "[[()]\n",
        " [()]]\n",
        "(2, 1)\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m = tuple([1,2,3,3])\n",
      "type(m)\n",
      "print m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1, 2, 3, 3)\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m = [None for _ in range(10)]\n",
      "m[5] = 5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out = createRecArray(hdfToWrite[hdfToWrite.keys()[0]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('2014-04-01 00:00:00.0', 1800, 21.529805774655536, 20.953231119594292, 21.90330409672651, 0.05863279566792817, 0.005707343985696955, 0.01864778738050875), ('2014-04-01 00:30:00.0', 1800, 20.124213100125626, 19.31790786313792, 21.150252598602947, 0.35156291750185226, 0.013975433157704753, 0.04035539883428007)]\n",
        "(147,)\n",
        "147\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out.shape\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "(147, 1)"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "struct_diffdtype = np.array([(1.0, 'string1', 2.0), (3.0, 'string2', 4.1)],\n",
      "dtype=[('x', float),('str_var', 'a7'),('y',float)])\n",
      "print('\\n structured array with different dtypes')\n",
      "print struct_diffdtype\n",
      "struct_diffdtype_nd = struct_diffdtype[['str_var', 'x', 'y']].view(np.ndarray).reshape(len(struct_diffdtype), -1)\n",
      "print struct_diffdtype_nd.shape\n",
      "print struct_diffdtype_nd\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " structured array with different dtypes\n",
        "[(1.0, 'string1', 2.0) (3.0, 'string2', 4.1)]\n",
        "(2, 1)\n",
        "[[('string1', 1.0, 2.0)]\n",
        " [('string2', 3.0, 4.1)]]\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out = createRecArray(hdfToWrite[hdfToWrite.keys()[0]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "(147, 7)"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt = np.dtype([('numPts','i4'),('mean','f8'),('min','f8'),('max','f8'),('variance','f8'),('stdErr','f8'),('uncertainty','f8')])\n",
      "#r = r[['numPts','mean','min','max','variance','stdErr','uncertainty']].view(np.ndarray).reshape(len(r), -1)\n",
      "out2 = np.array(out,dtype=dt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out2.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 57,
       "text": [
        "(147, 7)"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out2[:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 59,
       "text": [
        "array([[(1800, 1800.0, 1800.0, 1800.0, 1800.0, 1800.0, 1800.0),\n",
        "        (0, 0.01864778738050875, 0.01864778738050875, 0.01864778738050875, 0.01864778738050875, 0.01864778738050875, 0.01864778738050875),\n",
        "        (21, 21.529805774655536, 21.529805774655536, 21.529805774655536, 21.529805774655536, 21.529805774655536, 21.529805774655536),\n",
        "        (0, 0.005707343985696955, 0.005707343985696955, 0.005707343985696955, 0.005707343985696955, 0.005707343985696955, 0.005707343985696955),\n",
        "        (20, 20.953231119594292, 20.953231119594292, 20.953231119594292, 20.953231119594292, 20.953231119594292, 20.953231119594292),\n",
        "        (21, 21.90330409672651, 21.90330409672651, 21.90330409672651, 21.90330409672651, 21.90330409672651, 21.90330409672651),\n",
        "        (0, 0.05863279566792817, 0.05863279566792817, 0.05863279566792817, 0.05863279566792817, 0.05863279566792817, 0.05863279566792817)],\n",
        "       [(1800, 1800.0, 1800.0, 1800.0, 1800.0, 1800.0, 1800.0),\n",
        "        (0, 0.04035539883428007, 0.04035539883428007, 0.04035539883428007, 0.04035539883428007, 0.04035539883428007, 0.04035539883428007),\n",
        "        (20, 20.124213100125626, 20.124213100125626, 20.124213100125626, 20.124213100125626, 20.124213100125626, 20.124213100125626),\n",
        "        (0, 0.013975433157704753, 0.013975433157704753, 0.013975433157704753, 0.013975433157704753, 0.013975433157704753, 0.013975433157704753),\n",
        "        (19, 19.31790786313792, 19.31790786313792, 19.31790786313792, 19.31790786313792, 19.31790786313792, 19.31790786313792),\n",
        "        (21, 21.150252598602947, 21.150252598602947, 21.150252598602947, 21.150252598602947, 21.150252598602947, 21.150252598602947),\n",
        "        (0, 0.35156291750185226, 0.35156291750185226, 0.35156291750185226, 0.35156291750185226, 0.35156291750185226, 0.35156291750185226)],\n",
        "       [(1800, 1800.0, 1800.0, 1800.0, 1800.0, 1800.0, 1800.0),\n",
        "        (0, 0.03074764949515558, 0.03074764949515558, 0.03074764949515558, 0.03074764949515558, 0.03074764949515558, 0.03074764949515558),\n",
        "        (18, 18.419900039310924, 18.419900039310924, 18.419900039310924, 18.419900039310924, 18.419900039310924, 18.419900039310924),\n",
        "        (0, 0.01042270718758391, 0.01042270718758391, 0.01042270718758391, 0.01042270718758391, 0.01042270718758391, 0.01042270718758391),\n",
        "        (17, 17.80353950917723, 17.80353950917723, 17.80353950917723, 17.80353950917723, 17.80353950917723, 17.80353950917723),\n",
        "        (19, 19.356255019902058, 19.356255019902058, 19.356255019902058, 19.356255019902058, 19.356255019902058, 19.356255019902058),\n",
        "        (0, 0.195539085212604, 0.195539085212604, 0.195539085212604, 0.195539085212604, 0.195539085212604, 0.195539085212604)]], \n",
        "      dtype=[('numPts', '<i4'), ('mean', '<f8'), ('min', '<f8'), ('max', '<f8'), ('variance', '<f8'), ('stdErr', '<f8'), ('uncertainty', '<f8')])"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}